{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature_Engineering\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import col, count, sum\n",
    "# Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data and Convert to Spark Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'id,member_id,loan_amnt,funded_amnt,funded_amnt_inv,term,int_rate,installment,grade,sub_grade,emp_title,emp_length,home_ownership,annual_inc,verification_status,issue_d,loan_status,pymnt_plan,url,desc,purpose,title,zip_code,addr_state,dti,delinq_2yrs,earliest_cr_line,inq_last_6mths,mths_since_last_delinq,mths_since_last_record,open_acc,pub_rec,revol_bal,revol_util,total_acc,initial_list_status,out_prncp,out_prncp_inv,total_pymnt,total_pymnt_inv,total_rec_prncp,total_rec_int,total_rec_late_fee,recoveries,collection_recovery_fee,last_pymnt_d,last_pymnt_amnt,next_pymnt_d,last_credit_pull_d,collections_12_mths_ex_med,mths_since_last_major_derog,policy_code,application_type,annual_inc_joint,dti_joint,verification_status_joint,acc_now_delinq,tot_coll_amt,tot_cur_bal,open_acc_6m,open_il_6m,open_il_12m,open_il_24m,mths_since_rcnt_il,total_bal_il,il_util,open_rv_12m,open_rv_24m,max_bal_bc,all_util,total_rev_hi_lim,inq_fi,total_cu_tl,inq_last_12m']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read files\n",
    "sc.textFile(\"loan.csv\").take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data as dataframe\n",
    "loan_df=spark.read.csv(\"loan.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_df.rdd.getNumPartitions()\n",
    "type(loan_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create response variable and features\n",
    "### 3.1 Remove some columns based on EDA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loan_df2=loan_df.select(\n",
    "    loan_df.loan_amnt.cast(\"float\"),\n",
    "    loan_df.funded_amnt.cast(\"float\"),\n",
    "    loan_df.funded_amnt_inv.cast(\"float\"),\n",
    "    loan_df.int_rate.cast(\"float\"),  #convert to float\n",
    "    loan_df.installment.cast(\"float\"), #convert to float\n",
    "    'grade',\n",
    "    'sub_grade',   # NEED TO BE DUMMIED\n",
    "    'emp_length',\n",
    "    'home_ownership', #group & make it dummy, done \n",
    "    loan_df.annual_inc.cast(\"float\"),\n",
    "    # 'issue_d',  #why comment out?\n",
    "    'loan_status', \n",
    "    # response variable (pending for change after group discussion)\n",
    "    'purpose',  #make it dummy\n",
    "#     'zip_code', #interesting, worth dummying, might run into problems tho\n",
    "#     'addr_state', #dummy\n",
    "    'verification_status',\n",
    "#     'initial_list_status',\n",
    "    loan_df.dti.cast(\"float\"),#float done\n",
    "    loan_df.delinq_2yrs.cast(\"integer\"),  \n",
    "    #take out NAs, 2? 1, 3, mostly 0\n",
    "    # 'earliest_cr_line',\n",
    "    loan_df.inq_last_6mths.cast(\"integer\"), #similar to delingq_2yr\n",
    "    loan_df.open_acc.cast(\"integer\"), \n",
    "    loan_df.pub_rec.cast(\"integer\"), #what is it? 0,1\n",
    "    loan_df.revol_bal.cast(\"float\"), #done\n",
    "    loan_df.revol_util.cast(\"float\"),#done\n",
    "    loan_df.total_acc.cast(\"integer\"),\n",
    "    #loan_df.last_credit_pull_d.cast(\"integer\"), #date\n",
    "    loan_df.acc_now_delinq.cast(\"integer\"),#ok\n",
    "    loan_df.tot_coll_amt.cast(\"float\"), #done\n",
    "    loan_df.tot_cur_bal.cast(\"float\"), #done\n",
    "    loan_df.total_rev_hi_lim.cast(\"integer\") #what is this\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create response variable and remove rows with no valid response variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# needs to fix that, encoding doesn't seem to be right\n",
    "def whetherpaid(x):\n",
    "    if x in ['Default', 'Charged Off', 'Does not meet the credit policy. Status:Charged Off']:\n",
    "        return 1\n",
    "    elif x in ['Does not meet the credit policy. Status:Fully Paid', 'Fully Paid']:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paidflag = udf(lambda x: whetherpaid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#subject to change\n",
    "loan_df3 = loan_df2.withColumn(\n",
    "    'paid_flag',\n",
    "    paidflag('loan_status').cast(\"integer\")\n",
    "        ).where(\"paid_flag != -1\").drop('loan_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loan_amnt: float (nullable = true)\n",
      " |-- funded_amnt: float (nullable = true)\n",
      " |-- funded_amnt_inv: float (nullable = true)\n",
      " |-- int_rate: float (nullable = true)\n",
      " |-- installment: float (nullable = true)\n",
      " |-- grade: string (nullable = true)\n",
      " |-- sub_grade: string (nullable = true)\n",
      " |-- emp_length: string (nullable = true)\n",
      " |-- home_ownership: string (nullable = true)\n",
      " |-- annual_inc: float (nullable = true)\n",
      " |-- purpose: string (nullable = true)\n",
      " |-- verification_status: string (nullable = true)\n",
      " |-- dti: float (nullable = true)\n",
      " |-- delinq_2yrs: integer (nullable = true)\n",
      " |-- inq_last_6mths: integer (nullable = true)\n",
      " |-- open_acc: integer (nullable = true)\n",
      " |-- pub_rec: integer (nullable = true)\n",
      " |-- revol_bal: float (nullable = true)\n",
      " |-- revol_util: float (nullable = true)\n",
      " |-- total_acc: integer (nullable = true)\n",
      " |-- acc_now_delinq: integer (nullable = true)\n",
      " |-- tot_coll_amt: float (nullable = true)\n",
      " |-- tot_cur_bal: float (nullable = true)\n",
      " |-- total_rev_hi_lim: integer (nullable = true)\n",
      " |-- paid_flag: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loan_df3.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Add more features\n",
    "#### 3.3.1 Create a numeric feature for \"emp_length\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|emp_length|\n",
      "+----------+\n",
      "|   9 years|\n",
      "|   5 years|\n",
      "|    1 year|\n",
      "|       n/a|\n",
      "|   2 years|\n",
      "|   7 years|\n",
      "|   8 years|\n",
      "|   4 years|\n",
      "|   6 years|\n",
      "|   3 years|\n",
      "| 10+ years|\n",
      "|  < 1 year|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loan_df3.select('emp_length').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def convert_to_int(s):\n",
    "    s = re.sub('\\\\D', '', s)  #remove any non-digital character\n",
    "    #\\d matches any digital, #\\D matches any non-digital\n",
    "    try:\n",
    "        return s\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "emp_to_num = udf(convert_to_int)\n",
    "loan_df4 = loan_df3.withColumn('emp_len',emp_to_num('emp_length').cast('integer')).drop('emp_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|emp_len|\n",
      "+-------+\n",
      "|   null|\n",
      "|      1|\n",
      "|      6|\n",
      "|      3|\n",
      "|      5|\n",
      "|      9|\n",
      "|      4|\n",
      "|      8|\n",
      "|      7|\n",
      "|     10|\n",
      "|      2|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loan_df4.select('emp_len').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Create numeric variable for grade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+---+-----------+--------------+--------+-------+---------+----------+---------+\n",
      "|purpose|verification_status|dti|delinq_2yrs|inq_last_6mths|open_acc|pub_rec|revol_bal|revol_util|total_acc|\n",
      "+-------+-------------------+---+-----------+--------------+--------+-------+---------+----------+---------+\n",
      "|      0|                  0|252|        225|           198|     195|    161|      102|       314|       88|\n",
      "+-------+-------------------+---+-----------+--------------+--------+-------+---------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# count how many nulls in each column\n",
    "def count_null(c):\n",
    "    return sum(col(c).isNull().cast(\"integer\")).alias(c)\n",
    "\n",
    "exprs = [count_null(c) for c in loan_df4.columns[9:19]]\n",
    "loan_df4.agg(*exprs).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3 Create numeric variable for grade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|home_ownership|\n",
      "+--------------+\n",
      "|           OWN|\n",
      "|          RENT|\n",
      "|      MORTGAGE|\n",
      "|           ANY|\n",
      "|         OTHER|\n",
      "|          NONE|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loan_df4.select('home_ownership').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def home_ownership_func(x):\n",
    "    if x in ['ANY','OTHER','NONE']:\n",
    "        return 'Other'\n",
    "    else: \n",
    "        return x\n",
    "\n",
    "home_ownership = udf(home_ownership_func)  #fixed a function\n",
    "loan_df5 = loan_df4.withColumn('home_ownership',home_ownership('home_ownership'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+\n",
      "|home_ownership| count|\n",
      "+--------------+------+\n",
      "|           OWN| 22282|\n",
      "|         Other|   228|\n",
      "|          RENT|107831|\n",
      "|      MORTGAGE|126598|\n",
      "+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loan_df5.select('home_ownership').groupBy('home_ownership').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|home_ownership|\n",
      "+--------------+\n",
      "|           OWN|\n",
      "|         Other|\n",
      "|          RENT|\n",
      "|      MORTGAGE|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loan_df5.select('home_ownership').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.4 Add loan_inc_ratio feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_ratio(a, b):\n",
    "    try:\n",
    "        return a/float(b)\n",
    "    except TypeError:\n",
    "        return None\n",
    "    except ZeroDivisionError:\n",
    "        return None\n",
    "\n",
    "ratio = udf(calculate_ratio) #define a udf_function ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loan_df6 = loan_df5.withColumn(\n",
    "    'loan_inc_ratio',ratio('loan_amnt','annual_inc'\n",
    "                          ).cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loan_df7 = loan_df6.withColumn(\n",
    "    'instal_inc_ratio',\n",
    "    ratio('installment','annual_inc').cast('float'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.5 Add feature instal_inc_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_monthly_ratio(a, b):\n",
    "    try:\n",
    "        return a/(float(b)/12)\n",
    "    except TypeError:\n",
    "        return None\n",
    "    except ZeroDivisionError:\n",
    "        return None\n",
    "    \n",
    "monthly_ratio = udf(calculate_monthly_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loan_df8 = loan_df7.withColumn(\n",
    "    'instal_inc_ratio',\n",
    "    ratio('installment','annual_inc').cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loan_amnt: float (nullable = true)\n",
      " |-- funded_amnt: float (nullable = true)\n",
      " |-- funded_amnt_inv: float (nullable = true)\n",
      " |-- int_rate: float (nullable = true)\n",
      " |-- installment: float (nullable = true)\n",
      " |-- grade: string (nullable = true)\n",
      " |-- sub_grade: string (nullable = true)\n",
      " |-- home_ownership: string (nullable = true)\n",
      " |-- annual_inc: float (nullable = true)\n",
      " |-- purpose: string (nullable = true)\n",
      " |-- verification_status: string (nullable = true)\n",
      " |-- dti: float (nullable = true)\n",
      " |-- delinq_2yrs: integer (nullable = true)\n",
      " |-- inq_last_6mths: integer (nullable = true)\n",
      " |-- open_acc: integer (nullable = true)\n",
      " |-- pub_rec: integer (nullable = true)\n",
      " |-- revol_bal: float (nullable = true)\n",
      " |-- revol_util: float (nullable = true)\n",
      " |-- total_acc: integer (nullable = true)\n",
      " |-- acc_now_delinq: integer (nullable = true)\n",
      " |-- tot_coll_amt: float (nullable = true)\n",
      " |-- tot_cur_bal: float (nullable = true)\n",
      " |-- total_rev_hi_lim: integer (nullable = true)\n",
      " |-- paid_flag: integer (nullable = true)\n",
      " |-- emp_len: integer (nullable = true)\n",
      " |-- loan_inc_ratio: float (nullable = true)\n",
      " |-- instal_inc_ratio: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loan_df8.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.6 Create dummy variables\n",
    "* Use StringIndexer to encode a string column of labels to a column of label indices, and most frequent label gets index 0.\n",
    "\n",
    "* Use OneHotEncoder to convert indices into dummy vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "convert_list = [      \n",
    "               'purpose',\n",
    "               'grade',\n",
    "               'sub_grade',\n",
    "               'verification_status',\n",
    "               'home_ownership',\n",
    "                ]\n",
    "\n",
    "for item in convert_list:\n",
    "    indexer = StringIndexer(inputCol=item, outputCol=item + 'Index')    \n",
    "    loan_df8 = indexer.fit(loan_df8).transform(loan_df8).drop(item)\n",
    "    onehotenc = OneHotEncoder(inputCol=item + 'Index', outputCol=item+\"-onehot\", dropLast=False)\n",
    "    # we can experiment with True\n",
    "    loan_df8 = onehotenc.transform(loan_df8).drop(item+'Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.7 deal with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filling NA values with 0\n",
    "loan_df8 = loan_df8.fillna(0.0, ['tot_coll_amt','tot_cur_bal', 'total_rev_hi_lim'])\n",
    "# Drop rows with NA\n",
    "loan_df9 = loan_df8.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loan_amnt',\n",
       " 'funded_amnt',\n",
       " 'funded_amnt_inv',\n",
       " 'int_rate',\n",
       " 'installment',\n",
       " 'annual_inc',\n",
       " 'dti',\n",
       " 'delinq_2yrs',\n",
       " 'inq_last_6mths',\n",
       " 'open_acc',\n",
       " 'pub_rec',\n",
       " 'revol_bal',\n",
       " 'revol_util',\n",
       " 'total_acc',\n",
       " 'acc_now_delinq',\n",
       " 'tot_coll_amt',\n",
       " 'tot_cur_bal',\n",
       " 'total_rev_hi_lim',\n",
       " 'paid_flag',\n",
       " 'emp_len',\n",
       " 'loan_inc_ratio',\n",
       " 'instal_inc_ratio',\n",
       " 'purpose-onehot',\n",
       " 'grade-onehot',\n",
       " 'sub_grade-onehot',\n",
       " 'verification_status-onehot',\n",
       " 'home_ownership-onehot']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_df9.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|home_ownership-onehot|\n",
      "+---------------------+\n",
      "|        (4,[1],[1.0])|\n",
      "|        (4,[1],[1.0])|\n",
      "|        (4,[1],[1.0])|\n",
      "|        (4,[1],[1.0])|\n",
      "|        (4,[1],[1.0])|\n",
      "|        (4,[1],[1.0])|\n",
      "|        (4,[2],[1.0])|\n",
      "|        (4,[1],[1.0])|\n",
      "|        (4,[2],[1.0])|\n",
      "|        (4,[2],[1.0])|\n",
      "|        (4,[1],[1.0])|\n",
      "|        (4,[1],[1.0])|\n",
      "|        (4,[1],[1.0])|\n",
      "|        (4,[1],[1.0])|\n",
      "|        (4,[1],[1.0])|\n",
      "|        (4,[0],[1.0])|\n",
      "|        (4,[0],[1.0])|\n",
      "|        (4,[1],[1.0])|\n",
      "|        (4,[1],[1.0])|\n",
      "|        (4,[1],[1.0])|\n",
      "+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loan_df9.select('home_ownership-onehot').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loan_df_final = loan_df9.select(\n",
    " 'paid_flag',\n",
    " 'loan_amnt',\n",
    " 'funded_amnt',\n",
    " 'funded_amnt_inv',\n",
    " 'int_rate',\n",
    " 'installment',\n",
    " 'annual_inc',\n",
    " 'dti',\n",
    " 'delinq_2yrs',\n",
    " 'inq_last_6mths',\n",
    " 'open_acc',\n",
    " 'pub_rec',\n",
    " 'revol_bal',\n",
    " 'revol_util',\n",
    " 'total_acc',\n",
    " 'acc_now_delinq',\n",
    " 'tot_coll_amt',\n",
    " 'tot_cur_bal',\n",
    " 'total_rev_hi_lim',\n",
    " 'emp_len',\n",
    " 'loan_inc_ratio',\n",
    " 'instal_inc_ratio',\n",
    " 'purpose-onehot',\n",
    " 'grade-onehot',\n",
    " 'sub_grade-onehot',\n",
    " 'verification_status-onehot',\n",
    " 'home_ownership-onehot'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- paid_flag: integer (nullable = true)\n",
      " |-- loan_amnt: float (nullable = true)\n",
      " |-- funded_amnt: float (nullable = true)\n",
      " |-- funded_amnt_inv: float (nullable = true)\n",
      " |-- int_rate: float (nullable = true)\n",
      " |-- installment: float (nullable = true)\n",
      " |-- annual_inc: float (nullable = true)\n",
      " |-- dti: float (nullable = true)\n",
      " |-- delinq_2yrs: integer (nullable = true)\n",
      " |-- inq_last_6mths: integer (nullable = true)\n",
      " |-- open_acc: integer (nullable = true)\n",
      " |-- pub_rec: integer (nullable = true)\n",
      " |-- revol_bal: float (nullable = true)\n",
      " |-- revol_util: float (nullable = true)\n",
      " |-- total_acc: integer (nullable = true)\n",
      " |-- acc_now_delinq: integer (nullable = true)\n",
      " |-- tot_coll_amt: float (nullable = false)\n",
      " |-- tot_cur_bal: float (nullable = false)\n",
      " |-- total_rev_hi_lim: integer (nullable = true)\n",
      " |-- emp_len: integer (nullable = true)\n",
      " |-- loan_inc_ratio: float (nullable = true)\n",
      " |-- instal_inc_ratio: float (nullable = true)\n",
      " |-- purpose-onehot: vector (nullable = true)\n",
      " |-- grade-onehot: vector (nullable = true)\n",
      " |-- sub_grade-onehot: vector (nullable = true)\n",
      " |-- verification_status-onehot: vector (nullable = true)\n",
      " |-- home_ownership-onehot: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loan_df_final.take(1)\n",
    "loan_df_final.printSchema()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "count how many nulls in each column\n",
    "def count_null(c):\n",
    "    return sum(col(c).isNull().cast(\"integer\")).alias(c)\n",
    "\n",
    "exprs = [count_null(c) for c in loan_df9.columns]\n",
    "loan_df9.agg(*exprs).toPandas().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Instantiating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=0, loan_amnt=5000.0, funded_amnt=5000.0, funded_amnt_inv=4975.0, int_rate=10.649999618530273, installment=162.8699951171875, annual_inc=24000.0, dti=27.649999618530273, delinq_2yrs=0, inq_last_6mths=1, open_acc=3, pub_rec=0, revol_bal=13648.0, revol_util=83.69999694824219, total_acc=9, acc_now_delinq=0, tot_coll_amt=0.0, tot_cur_bal=0.0, total_rev_hi_lim=0, emp_len=10, loan_inc_ratio=0.2083333283662796, instal_inc_ratio=0.006786249577999115, purpose-onehot=SparseVector(265, {1: 1.0}), grade-onehot=SparseVector(7, {0: 1.0}), sub_grade-onehot=SparseVector(35, {3: 1.0}), verification_status-onehot=SparseVector(3, {0: 1.0}), home_ownership-onehot=SparseVector(4, {1: 1.0})),\n",
       " Row(label=1, loan_amnt=2500.0, funded_amnt=2500.0, funded_amnt_inv=2500.0, int_rate=15.270000457763672, installment=59.83000183105469, annual_inc=30000.0, dti=1.0, delinq_2yrs=0, inq_last_6mths=5, open_acc=3, pub_rec=0, revol_bal=1687.0, revol_util=9.399999618530273, total_acc=4, acc_now_delinq=0, tot_coll_amt=0.0, tot_cur_bal=0.0, total_rev_hi_lim=0, emp_len=1, loan_inc_ratio=0.0833333358168602, instal_inc_ratio=0.0019943334627896547, purpose-onehot=SparseVector(265, {6: 1.0}), grade-onehot=SparseVector(7, {1: 1.0}), sub_grade-onehot=SparseVector(35, {7: 1.0}), verification_status-onehot=SparseVector(3, {2: 1.0}), home_ownership-onehot=SparseVector(4, {1: 1.0}))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Split the data into training and test sets (30% held out for testing)\n",
    "loan_df=loan_df_final.withColumnRenamed('paid_flag','label')\n",
    "loan_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "va=VectorAssembler(outputCol='features',inputCols=loan_df.columns[1:])\n",
    "data=va.transform(loan_df).select('features','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=SparseVector(335, {0: 5000.0, 1: 5000.0, 2: 4975.0, 3: 10.65, 4: 162.87, 5: 24000.0, 6: 27.65, 8: 1.0, 9: 3.0, 11: 13648.0, 12: 83.7, 13: 9.0, 18: 10.0, 19: 0.2083, 20: 0.0068, 22: 1.0, 286: 1.0, 296: 1.0, 328: 1.0, 332: 1.0}), label=0),\n",
       " Row(features=SparseVector(335, {0: 2500.0, 1: 2500.0, 2: 2500.0, 3: 15.27, 4: 59.83, 5: 30000.0, 6: 1.0, 8: 5.0, 9: 3.0, 11: 1687.0, 12: 9.4, 13: 4.0, 18: 1.0, 19: 0.0833, 20: 0.002, 27: 1.0, 287: 1.0, 300: 1.0, 330: 1.0, 332: 1.0}), label=1),\n",
       " Row(features=SparseVector(335, {0: 2400.0, 1: 2400.0, 2: 2400.0, 3: 15.96, 4: 84.33, 5: 12252.0, 6: 8.72, 8: 2.0, 9: 2.0, 11: 2956.0, 12: 98.5, 13: 10.0, 18: 10.0, 19: 0.1959, 20: 0.0069, 26: 1.0, 287: 1.0, 303: 1.0, 329: 1.0, 332: 1.0}), label=0)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(335,[0,1,2,3,4,5...|    0|\n",
      "|(335,[0,1,2,3,4,5...|    1|\n",
      "|(335,[0,1,2,3,4,5...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating Training and Test Data\n",
    "data_sets=data.randomSplit([0.8,0.2])\n",
    "data_train=data_sets[0].cache()\n",
    "data_test=data_sets[1].cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit random forest\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "rfmodel=rf.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|(335,[0,1,2,3,4,5...|    0|[15.9549480633131...|[0.79774740316565...|       0.0|\n",
      "|(335,[0,1,2,3,4,5...|    0|[14.1290173051074...|[0.70645086525537...|       0.0|\n",
      "|(335,[0,1,2,3,4,5...|    0|[15.6197347295825...|[0.78098673647912...|       0.0|\n",
      "|(335,[0,1,2,3,4,5...|    0|[17.5381664912275...|[0.87690832456137...|       0.0|\n",
      "|(335,[0,1,2,3,4,5...|    0|[17.1375076870517...|[0.85687538435258...|       0.0|\n",
      "|(335,[0,1,2,3,4,5...|    0|[16.0960367814478...|[0.80480183907239...|       0.0|\n",
      "|(335,[0,1,2,3,4,5...|    0|[16.2802870344192...|[0.81401435172096...|       0.0|\n",
      "|(335,[0,1,2,3,4,5...|    0|[17.0815210619768...|[0.85407605309884...|       0.0|\n",
      "|(335,[0,1,2,3,4,5...|    0|[16.7394747907107...|[0.83697373953553...|       0.0|\n",
      "|(335,[0,1,2,3,4,5...|    1|[15.7875730509747...|[0.78937865254873...|       0.0|\n",
      "|(335,[0,1,2,3,4,5...|    1|[15.5754191427731...|[0.77877095713865...|       0.0|\n",
      "|(335,[0,1,2,3,4,5...|    0|[16.1402982583102...|[0.80701491291551...|       0.0|\n",
      "|(335,[0,1,2,3,4,5...|    1|[15.5058487597863...|[0.77529243798931...|       0.0|\n",
      "|(335,[0,1,2,3,4,5...|    0|[17.0818498090896...|[0.85409249045448...|       0.0|\n",
      "|(335,[0,1,2,3,4,5...|    0|[17.1818308040287...|[0.85909154020143...|       0.0|\n",
      "|(335,[0,1,2,3,4,5...|    0|[17.0179391657238...|[0.85089695828619...|       0.0|\n",
      "|(335,[0,1,2,3,4,5...|    0|[16.9375328798953...|[0.84687664399476...|       0.0|\n",
      "|(335,[0,1,2,3,4,5...|    1|[16.6127679854048...|[0.83063839927024...|       0.0|\n",
      "|(335,[0,1,2,3,4,5...|    0|[17.2967930313318...|[0.86483965156659...|       0.0|\n",
      "|(335,[0,1,2,3,4,5...|    0|[16.9184462088102...|[0.84592231044051...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions.\n",
    "predictions = rfmodel.transform(data_test)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Measure the performace: The Validation set approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC:0.691452102764\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model. metric: Area Under ROC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "bceval = BinaryClassificationEvaluator()\n",
    "print (bceval.getMetricName() + \":\" + str(bceval.evaluate(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderPR:0.322841141042\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model. metric: Area Under PR\n",
    "bceval.setMetricName(\"areaUnderPR\")\n",
    "print (bceval.getMetricName() + \":\" + str(bceval.evaluate(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3 OverSampling the data to solve unbalanced data problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training dataset fraud propotition: 0.180889657867\n"
     ]
    }
   ],
   "source": [
    "print 'training dataset fraud propotition:', float(data_train.filter('label=1').count())/float((data_train.filter('label=1').count() + data_train.filter('label=0').count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset fraud propotition: 0.179765039498\n"
     ]
    }
   ],
   "source": [
    "print 'test dataset fraud propotition:', float(data_test.filter('label=1').count())/float((data_test.filter('label=1').count() + data_test.filter('label=0').count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train_paid = data_train.filter(data_train.label == 0)\n",
    "data_train_not_paid = data_train.filter(data_train.label == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_samples_train = data_train.count()\n",
    "half_num_samples_train = num_samples_train / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train_paid = data_train_paid.sample(True, float(half_num_samples_train) / float(data_train_paid.count())) \n",
    "data_train_not_paid = data_train_not_paid.sample(True, float(half_num_samples_train) / float(data_train_not_paid.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98328"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_paid.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98789"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_not_paid.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = data_train_paid.union(data_train_not_paid)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.4 Parameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# n-fold validation and the results.\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "cv = CrossValidator().setEstimator(rf).setEvaluator(bceval).setNumFolds(5)\n",
    "paramGrid = ParamGridBuilder().addGrid(rf.numTrees,[10,25]).addGrid(rf.maxDepth,[15,20]).build()\n",
    "cv.setEstimatorParamMaps(paramGrid)\n",
    "cvmodel = cv.fit(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.5 Measure the bset model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Measure the performace\n",
    "print 'areaunderROC', BinaryClassificationEvaluator().evaluate(cvmodel.bestModel.transform(data_test))\n",
    "print 'areunderPR', BinaryClassificationEvaluator().setMetricName(\"areaUnderPR\").evaluate(cvmodel.bestModel.transform(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get predict,label tuple method 1\n",
    "predict_label_list = predictions.select('label','prediction').collect()\n",
    "predictionAndLabels = [(float(i[1]),float(i[0])) for i in predict_label_list]\n",
    "metrics = MulticlassMetrics(sc.parallelize(predictionAndLabels))\n",
    "print 'Confusion Matrix:/n', metrics.confusionMatrix().toArray()\n",
    "print 'percision rate:', metrics.precision(1)\n",
    "print 'recall rate:', metrics.recall(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.6 Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfmodel=cvmodel.bestModel\n",
    "importance_list = list(enumerate(rfmodel.featureImportances))\n",
    "importance_list.sort(key=lambda tup: -tup[1])\n",
    "top_importances = importance_list[:15]\n",
    "top_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # visiualize the importance \n",
    "# std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "#              axis=0)\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# # Print the feature ranking\n",
    "# print(\"Feature ranking:\")\n",
    "\n",
    "# for f in range(X.shape[1]):\n",
    "#     print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# # Plot the feature importances of the forest\n",
    "# plt.figure()\n",
    "# plt.title(\"Feature importances\")\n",
    "# plt.bar(range(X.shape[1]), importances[indices],\n",
    "#        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "# plt.xticks(range(X.shape[1]), indices)\n",
    "# plt.xlim([-1, X.shape[1]])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "lr=LogisticRegression()\n",
    "evaluator=BinaryClassificationEvaluator()\n",
    "\n",
    "cv=CrossValidator().setEstimator(lr).setEvaluator(evaluator).setNumFolds(5)\n",
    "paramGrid=ParamGridBuilder().addGrid(lr.maxIter,[100]).addGrid(lr.regParam,[0.1,0.01,0.001,1]).build()\n",
    "\n",
    "cv.setEstimatorParamMaps(paramGrid)\n",
    "cvmodel=cv.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions=cvmodel.bestModel.transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print predictions.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score=evaluator.evaluate(cvmodel.bestModel.transform(data_test))\n",
    "print evaluator.getMetricName()+\":\"+str(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_list = predictions.collect()\n",
    "predictionAndLabels = []\n",
    "for item in prediction_list:\n",
    "    predictionAndLabels.append((float(item[4]), float(item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics = MulticlassMetrics(sc.parallelize(predictionAndLabels))\n",
    "print metrics.confusionMatrix().toArray()\n",
    "print metrics.precision(1)\n",
    "print metrics.recall(1)\n",
    "print metrics.accuracy"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
