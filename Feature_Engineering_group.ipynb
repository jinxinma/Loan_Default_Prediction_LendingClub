{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature_Engineering\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import col, count, sum\n",
    "# Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from pyspark.ml.feature import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data and Convert to Spark Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'id,member_id,loan_amnt,funded_amnt,funded_amnt_inv,term,int_rate,installment,grade,sub_grade,emp_title,emp_length,home_ownership,annual_inc,verification_status,issue_d,loan_status,pymnt_plan,url,desc,purpose,title,zip_code,addr_state,dti,delinq_2yrs,earliest_cr_line,inq_last_6mths,mths_since_last_delinq,mths_since_last_record,open_acc,pub_rec,revol_bal,revol_util,total_acc,initial_list_status,out_prncp,out_prncp_inv,total_pymnt,total_pymnt_inv,total_rec_prncp,total_rec_int,total_rec_late_fee,recoveries,collection_recovery_fee,last_pymnt_d,last_pymnt_amnt,next_pymnt_d,last_credit_pull_d,collections_12_mths_ex_med,mths_since_last_major_derog,policy_code,application_type,annual_inc_joint,dti_joint,verification_status_joint,acc_now_delinq,tot_coll_amt,tot_cur_bal,open_acc_6m,open_il_6m,open_il_12m,open_il_24m,mths_since_rcnt_il,total_bal_il,il_util,open_rv_12m,open_rv_24m,max_bal_bc,all_util,total_rev_hi_lim,inq_fi,total_cu_tl,inq_last_12m']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read files\n",
    "sc.textFile(\"loan.csv\").take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data as dataframe\n",
    "loan_df=spark.read.csv(\"loan.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_df.rdd.getNumPartitions()\n",
    "type(loan_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create response variable and features\n",
    "### 3.1 Remove some columns based on EDA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loan_df1 = loan_df.drop('desc','mths_since_last_delinq','mths_since_last_record','next_pymnt_d',\n",
    "#                         'mths_since_last_major_derog','annual_inc_joint','dti_joint','verification_status_joint',\n",
    "#                         'open_acc_6m','open_il_6m','open_il_12m','open_il_24m','mths_since_rcnt_il','total_bal_il',\n",
    "#                         'il_util','open_rv_12m','open_rv_24m','max_bal_bc','all_util','inq_fi','total_cu_tl',\n",
    "#                         'inq_last_12m', # with a lot NA\n",
    "#                         'id','member_id','collection_recovery_fee','last_pymnt_amnt','last_pymnt_d','out_prncp','out_prncp_inv',\n",
    "#                         'pymnt_plan','recoveries','term','title','total_pymnt','total_pymnt_inv','total_rec_int',\n",
    "#                         'total_rec_late_fee','total_rec_prncp','url','verification_status', 'initial_list_status', \n",
    "#                         'last_credit_pull_d','policy_code','emp_title','last_credit_pull_d' # domain knowledge\n",
    "#                        )\n",
    "\n",
    "#is that intentionally not leaving out drops?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print loan_df1.head(1)\n",
    "# print len(loan_df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loan_df2=loan_df.select(\n",
    "    loan_df.loan_amnt.cast(\"float\"),\n",
    "    loan_df.funded_amnt.cast(\"float\"),\n",
    "    loan_df.funded_amnt_inv.cast(\"float\"),\n",
    "    loan_df.int_rate.cast(\"float\"),  #convert to float\n",
    "    loan_df.installment.cast(\"float\"), #convert to float\n",
    "    'grade',\n",
    "    'sub_grade',   # NEED TO BE DUMMIED\n",
    "    'emp_length',\n",
    "    'home_ownership', #group & make it dummy, done \n",
    "    loan_df.annual_inc.cast(\"float\"),\n",
    "    # 'issue_d',  #why comment out?\n",
    "    'loan_status', \n",
    "    # response variable (pending for change after group discussion)\n",
    "    'purpose',  #make it dummy\n",
    "#     'zip_code', #interesting, worth dummying, might run into problems tho\n",
    "#     'addr_state', #dummy\n",
    "    'verification_status',\n",
    "#     'initial_list_status',\n",
    "    loan_df.dti.cast(\"float\"),#float done\n",
    "    loan_df.delinq_2yrs.cast(\"integer\"),  \n",
    "    #take out NAs, 2? 1, 3, mostly 0\n",
    "    # 'earliest_cr_line',\n",
    "    loan_df.inq_last_6mths.cast(\"integer\"), #similar to delingq_2yr\n",
    "    loan_df.open_acc.cast(\"integer\"), \n",
    "    loan_df.pub_rec.cast(\"integer\"), #what is it? 0,1\n",
    "    loan_df.revol_bal.cast(\"float\"), #done\n",
    "    loan_df.revol_util.cast(\"float\"),#done\n",
    "    loan_df.total_acc.cast(\"integer\"),\n",
    "    #loan_df.last_credit_pull_d.cast(\"integer\"), #date\n",
    "    loan_df.acc_now_delinq.cast(\"integer\"),#ok\n",
    "    loan_df.tot_coll_amt.cast(\"float\"), #done\n",
    "    loan_df.tot_cur_bal.cast(\"float\"), #done\n",
    "    loan_df.total_rev_hi_lim.cast(\"integer\") #what is this\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create response variable and remove rows with no valid response variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# needs to fix that, encoding doesn't seem to be right\n",
    "\n",
    "def whetherpaid(x):\n",
    "    if x in ['Default', 'Charged Off', 'Does not meet the credit policy. Status:Charged Off']:\n",
    "        return 1\n",
    "    elif x in ['Does not meet the credit policy. Status:Fully Paid', 'Fully Paid']:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paidflag = udf(lambda x: whetherpaid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#subject to change\n",
    "loan_df3 = loan_df2.withColumn(\n",
    "    'paid_flag',\n",
    "    paidflag('loan_status').cast(\"integer\")\n",
    "        ).where(\"paid_flag != -1\").drop('loan_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loan_amnt: float (nullable = true)\n",
      " |-- funded_amnt: float (nullable = true)\n",
      " |-- funded_amnt_inv: float (nullable = true)\n",
      " |-- int_rate: float (nullable = true)\n",
      " |-- installment: float (nullable = true)\n",
      " |-- grade: string (nullable = true)\n",
      " |-- sub_grade: string (nullable = true)\n",
      " |-- emp_length: string (nullable = true)\n",
      " |-- home_ownership: string (nullable = true)\n",
      " |-- annual_inc: float (nullable = true)\n",
      " |-- purpose: string (nullable = true)\n",
      " |-- verification_status: string (nullable = true)\n",
      " |-- dti: float (nullable = true)\n",
      " |-- delinq_2yrs: integer (nullable = true)\n",
      " |-- inq_last_6mths: integer (nullable = true)\n",
      " |-- open_acc: integer (nullable = true)\n",
      " |-- pub_rec: integer (nullable = true)\n",
      " |-- revol_bal: float (nullable = true)\n",
      " |-- revol_util: float (nullable = true)\n",
      " |-- total_acc: integer (nullable = true)\n",
      " |-- acc_now_delinq: integer (nullable = true)\n",
      " |-- tot_coll_amt: float (nullable = true)\n",
      " |-- tot_cur_bal: float (nullable = true)\n",
      " |-- total_rev_hi_lim: integer (nullable = true)\n",
      " |-- paid_flag: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loan_df3.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Add more features\n",
    "#### 3.3.1 Create a numeric feature for \"emp_length\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def convert_to_int(s):\n",
    "    s = re.sub('\\\\D', '', s)  #remove any non-digital character\n",
    "    #\\d matches any digital, #\\D matches any non-digital\n",
    "    try:\n",
    "        return s\n",
    "    except ValueError:\n",
    "        return 'NaN'\n",
    "\n",
    "emp_to_num = udf(convert_to_int)\n",
    "loan_df4 = loan_df3.withColumn('emp_len',emp_to_num('emp_length').cast('integer')).drop('emp_length')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Create numeric variable for grade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+---------------+--------+-----------+-----+---------+--------------+----------+\n",
      "|loan_amnt|funded_amnt|funded_amnt_inv|int_rate|installment|grade|sub_grade|home_ownership|annual_inc|\n",
      "+---------+-----------+---------------+--------+-----------+-----+---------+--------------+----------+\n",
      "|        0|          0|              0|       0|          0|    0|        0|             0|         4|\n",
      "+---------+-----------+---------------+--------+-----------+-----+---------+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# count how many nulls in each column\n",
    "def count_null(c):\n",
    "    return sum(col(c).isNull().cast(\"integer\")).alias(c)\n",
    "\n",
    "exprs = [count_null(c) for c in loan_df4.columns[0:9]]\n",
    "loan_df4.agg(*exprs).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3 Create numeric variable for grade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def home_ownership_func(x):\n",
    "    if x in ['ANY','OTHER','NONE']:\n",
    "        return 'Other'\n",
    "    else: \n",
    "        return x\n",
    "\n",
    "home_ownership = udf(home_ownership_func)  #fixed a function\n",
    "loan_df5 = loan_df4.withColumn('home_ownership',home_ownership('home_ownership'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+\n",
      "|home_ownership| count|\n",
      "+--------------+------+\n",
      "|           OWN| 22282|\n",
      "|         Other|   228|\n",
      "|          RENT|107831|\n",
      "|      MORTGAGE|126598|\n",
      "+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loan_df5.select('home_ownership').groupBy('home_ownership').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.4 Add loan_inc_ratio feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_ratio(a, b):\n",
    "    try:\n",
    "        return a/float(b)\n",
    "    except TypeError:\n",
    "        return None\n",
    "    except ZeroDivisionError:\n",
    "        return None\n",
    "\n",
    "ratio = udf(calculate_ratio) #define a udf_function ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loan_df6 = loan_df5.withColumn(\n",
    "    'loan_inc_ratio',ratio('loan_amnt','annual_inc'\n",
    "                          ).cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loan_df7 = loan_df6.withColumn(\n",
    "    'instal_inc_ratio',\n",
    "    ratio('installment','annual_inc').cast('float'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.5 Add feature instal_inc_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_monthly_ratio(a, b):\n",
    "    try:\n",
    "        return a/(float(b)/12)\n",
    "    except TypeError:\n",
    "        return None\n",
    "    except ZeroDivisionError:\n",
    "        return None\n",
    "    \n",
    "monthly_ratio = udf(calculate_monthly_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loan_df8 = loan_df7.withColumn(\n",
    "    'instal_inc_ratio',\n",
    "    ratio('installment','annual_inc').cast('float'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.6 Create dummy variables\n",
    "* Use StringIndexer to encode a string column of labels to a column of label indices, and most frequent label gets index 0.\n",
    "\n",
    "* Use OneHotEncoder to convert indices into dummy vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purpose\n",
      "purpose\n",
      "grade\n",
      "grade\n",
      "sub_grade\n",
      "sub_grade\n",
      "verification_status\n",
      "verification_status\n",
      "home_ownership\n",
      "home_ownership\n"
     ]
    }
   ],
   "source": [
    "convert_list = [      \n",
    "               'purpose',\n",
    "               'grade',\n",
    "               'sub_grade',\n",
    "               'verification_status',\n",
    "               'home_ownership',\n",
    "                ]\n",
    "\n",
    "for item in convert_list:\n",
    "    print item\n",
    "    indexer = StringIndexer(inputCol=item, outputCol=item + 'Index')    \n",
    "    loan_df8 = indexer.fit(loan_df8).transform(loan_df8).drop(item)\n",
    "    onehotenc = OneHotEncoder(inputCol=item + 'Index', outputCol=item+\"-onehot\", dropLast=False)\n",
    "    # we can experiment with True\n",
    "    loan_df8 = onehotenc.transform(loan_df8).drop(item+'Index')\n",
    "    print item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loan_df8 = loan_df8.fillna(0.0, ['tot_coll_amt','tot_cur_bal', 'total_rev_hi_lim'])\n",
    "loan_df9 = loan_df8.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loan_amnt',\n",
       " 'funded_amnt',\n",
       " 'funded_amnt_inv',\n",
       " 'int_rate',\n",
       " 'installment',\n",
       " 'annual_inc',\n",
       " 'dti',\n",
       " 'delinq_2yrs',\n",
       " 'inq_last_6mths',\n",
       " 'open_acc',\n",
       " 'pub_rec',\n",
       " 'revol_bal',\n",
       " 'revol_util',\n",
       " 'total_acc',\n",
       " 'acc_now_delinq',\n",
       " 'tot_coll_amt',\n",
       " 'tot_cur_bal',\n",
       " 'total_rev_hi_lim',\n",
       " 'paid_flag',\n",
       " 'emp_len',\n",
       " 'loan_inc_ratio',\n",
       " 'instal_inc_ratio',\n",
       " 'purpose-onehot',\n",
       " 'grade-onehot',\n",
       " 'sub_grade-onehot',\n",
       " 'verification_status-onehot',\n",
       " 'home_ownership-onehot']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_df9.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loan_df_final = loan_df9.select(\n",
    " 'paid_flag',\n",
    " 'loan_amnt',\n",
    " 'funded_amnt',\n",
    " 'funded_amnt_inv',\n",
    " 'int_rate',\n",
    " 'installment',\n",
    " 'annual_inc',\n",
    " 'dti',\n",
    " 'delinq_2yrs',\n",
    " 'inq_last_6mths',\n",
    " 'open_acc',\n",
    " 'pub_rec',\n",
    " 'revol_bal',\n",
    " 'revol_util',\n",
    " 'total_acc',\n",
    " 'acc_now_delinq',\n",
    " 'tot_coll_amt',\n",
    " 'tot_cur_bal',\n",
    " 'total_rev_hi_lim',\n",
    " 'emp_len',\n",
    " 'loan_inc_ratio',\n",
    " 'instal_inc_ratio',\n",
    " 'purpose-onehot',\n",
    " 'grade-onehot',\n",
    " 'sub_grade-onehot',\n",
    " 'verification_status-onehot',\n",
    " 'home_ownership-onehot'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- paid_flag: integer (nullable = true)\n",
      " |-- loan_amnt: float (nullable = true)\n",
      " |-- funded_amnt: float (nullable = true)\n",
      " |-- funded_amnt_inv: float (nullable = true)\n",
      " |-- int_rate: float (nullable = true)\n",
      " |-- installment: float (nullable = true)\n",
      " |-- annual_inc: float (nullable = true)\n",
      " |-- dti: float (nullable = true)\n",
      " |-- delinq_2yrs: integer (nullable = true)\n",
      " |-- inq_last_6mths: integer (nullable = true)\n",
      " |-- open_acc: integer (nullable = true)\n",
      " |-- pub_rec: integer (nullable = true)\n",
      " |-- revol_bal: float (nullable = true)\n",
      " |-- revol_util: float (nullable = true)\n",
      " |-- total_acc: integer (nullable = true)\n",
      " |-- acc_now_delinq: integer (nullable = true)\n",
      " |-- tot_coll_amt: float (nullable = false)\n",
      " |-- tot_cur_bal: float (nullable = false)\n",
      " |-- total_rev_hi_lim: integer (nullable = true)\n",
      " |-- emp_len: integer (nullable = true)\n",
      " |-- loan_inc_ratio: float (nullable = true)\n",
      " |-- instal_inc_ratio: float (nullable = true)\n",
      " |-- purpose-onehot: vector (nullable = true)\n",
      " |-- grade-onehot: vector (nullable = true)\n",
      " |-- sub_grade-onehot: vector (nullable = true)\n",
      " |-- verification_status-onehot: vector (nullable = true)\n",
      " |-- home_ownership-onehot: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loan_df_final.take(1)\n",
    "loan_df_final.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count how many nulls in each column\n",
    "# def count_null(c):\n",
    "#     return sum(col(c).isNull().cast(\"integer\")).alias(c)\n",
    "\n",
    "# exprs = [count_null(c) for c in loan_df9.columns]\n",
    "# loan_df9.agg(*exprs).toPandas().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Instantiating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from pyspark.mllib.tree import RandomForest, RandomForestModel\n",
    "# from pyspark.mllib.util import MLUtils\n",
    "# from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "# # Load and parse the data file into an RDD of LabeledPoint.\n",
    "# data = loan_df_final.rdd.map(lambda row: LabeledPoint(row[0], row[1:]))\n",
    "# # Split the data into training and test sets (30% held out for testing)\n",
    "# (trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# model = RandomForest.trainClassifier(trainingData, numClasses=2, categoricalFeaturesInfo={},\n",
    "#                                      numTrees=11, featureSubsetStrategy=\"auto\",\n",
    "#                                      impurity='gini', maxDepth=15, maxBins=32)\n",
    "\n",
    "# # Evaluate model on test instances and compute test error\n",
    "# predictions = model.predict(testData.map(lambda x: x.features))\n",
    "# labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\n",
    "# testErr = labelsAndPredictions.filter(lambda (v, p): v != p).count() / float(testData.count())\n",
    "# print('Test Error = ' + str(testErr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=0, loan_amnt=5000.0, funded_amnt=5000.0, funded_amnt_inv=4975.0, int_rate=10.649999618530273, installment=162.8699951171875, annual_inc=24000.0, dti=27.649999618530273, delinq_2yrs=0, inq_last_6mths=1, open_acc=3, pub_rec=0, revol_bal=13648.0, revol_util=83.69999694824219, total_acc=9, acc_now_delinq=0, tot_coll_amt=0.0, tot_cur_bal=0.0, total_rev_hi_lim=0, emp_len=10, loan_inc_ratio=0.2083333283662796, instal_inc_ratio=0.006786249577999115, purpose-onehot=SparseVector(265, {1: 1.0}), grade-onehot=SparseVector(7, {0: 1.0}), sub_grade-onehot=SparseVector(35, {3: 1.0}), verification_status-onehot=SparseVector(3, {0: 1.0}), home_ownership-onehot=SparseVector(4, {1: 1.0})),\n",
       " Row(label=1, loan_amnt=2500.0, funded_amnt=2500.0, funded_amnt_inv=2500.0, int_rate=15.270000457763672, installment=59.83000183105469, annual_inc=30000.0, dti=1.0, delinq_2yrs=0, inq_last_6mths=5, open_acc=3, pub_rec=0, revol_bal=1687.0, revol_util=9.399999618530273, total_acc=4, acc_now_delinq=0, tot_coll_amt=0.0, tot_cur_bal=0.0, total_rev_hi_lim=0, emp_len=1, loan_inc_ratio=0.0833333358168602, instal_inc_ratio=0.0019943334627896547, purpose-onehot=SparseVector(265, {6: 1.0}), grade-onehot=SparseVector(7, {1: 1.0}), sub_grade-onehot=SparseVector(35, {7: 1.0}), verification_status-onehot=SparseVector(3, {2: 1.0}), home_ownership-onehot=SparseVector(4, {1: 1.0}))]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Split the data into training and test sets (30% held out for testing)\n",
    "loan_df=loan_df_final.withColumnRenamed('paid_flag','label')\n",
    "loan_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "va=VectorAssembler(outputCol='features',inputCols=loan_df.columns[:])\n",
    "data=va.transform(loan_df).select('features','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=SparseVector(336, {1: 5000.0, 2: 5000.0, 3: 4975.0, 4: 10.65, 5: 162.87, 6: 24000.0, 7: 27.65, 9: 1.0, 10: 3.0, 12: 13648.0, 13: 83.7, 14: 9.0, 19: 10.0, 20: 0.2083, 21: 0.0068, 23: 1.0, 287: 1.0, 297: 1.0, 329: 1.0, 333: 1.0}), label=0),\n",
       " Row(features=SparseVector(336, {0: 1.0, 1: 2500.0, 2: 2500.0, 3: 2500.0, 4: 15.27, 5: 59.83, 6: 30000.0, 7: 1.0, 9: 5.0, 10: 3.0, 12: 1687.0, 13: 9.4, 14: 4.0, 19: 1.0, 20: 0.0833, 21: 0.002, 28: 1.0, 288: 1.0, 301: 1.0, 331: 1.0, 333: 1.0}), label=1),\n",
       " Row(features=SparseVector(336, {1: 2400.0, 2: 2400.0, 3: 2400.0, 4: 15.96, 5: 84.33, 6: 12252.0, 7: 8.72, 9: 2.0, 10: 2.0, 12: 2956.0, 13: 98.5, 14: 10.0, 19: 10.0, 20: 0.1959, 21: 0.0069, 27: 1.0, 288: 1.0, 304: 1.0, 330: 1.0, 333: 1.0}), label=0)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(336,[1,2,3,4,5,6...|    0|\n",
      "|(336,[0,1,2,3,4,5...|    1|\n",
      "|(336,[1,2,3,4,5,6...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating Training and Test Data\n",
    "data_sets=data.randomSplit([0.8,0.2])\n",
    "data_train=data_sets[0].cache()\n",
    "data_test=data_sets[1].cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Training the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit random forest\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\",maxDepth=15)\n",
    "rfmodel=rf.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|(336,[0,1,2,3,4,5...|    1|[4.63200978186682...|[0.23160048909334...|       1.0|\n",
      "|(336,[0,1,2,3,4,5...|    1|[9.04460715706085...|[0.45223035785304...|       1.0|\n",
      "|(336,[0,1,2,3,4,5...|    1|[6.75234405914103...|[0.33761720295705...|       1.0|\n",
      "|(336,[0,1,2,3,4,5...|    1|[6.27942947355296...|[0.31397147367764...|       1.0|\n",
      "|(336,[0,1,2,3,4,5...|    1|[5.05801471763658...|[0.25290073588182...|       1.0|\n",
      "|(336,[0,1,2,3,4,5...|    1|[10.6186470338651...|[0.53093235169325...|       0.0|\n",
      "|(336,[0,1,2,3,4,5...|    1|[6.82247387248063...|[0.34112369362403...|       1.0|\n",
      "|(336,[0,1,2,3,4,5...|    1|[5.38044604108332...|[0.26902230205416...|       1.0|\n",
      "|(336,[0,1,2,3,4,5...|    1|[6.98734159310858...|[0.34936707965542...|       1.0|\n",
      "|(336,[0,1,2,3,4,5...|    1|[7.05669183498421...|[0.35283459174921...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions.\n",
    "predictions = rfmodel.transform(data_test)\n",
    "predictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0140983\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_list = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(features=SparseVector(336, {0: 1.0, 1: 12000.0, 2: 12000.0, 3: 12000.0, 4: 12.99, 5: 404.27, 6: 42000.0, 7: 21.36, 8: 1.0, 9: 1.0, 10: 20.0, 11: 1.0, 12: 4544.0, 13: 21.6, 14: 48.0, 16: 111.0, 17: 20176.0, 18: 21000.0, 19: 1.0, 20: 0.2857, 21: 0.0096, 22: 1.0, 287: 1.0, 295: 1.0, 331: 1.0, 333: 1.0}), label=1, rawPrediction=DenseVector([4.632, 15.368]), probability=DenseVector([0.2316, 0.7684]), prediction=1.0)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_list[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictionAndLabels = []\n",
    "for item in prediction_list:\n",
    "    predictionAndLabels.append((float(item[4]), float(item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 40409.      0.]\n",
      " [   684.   8192.]]\n",
      "1.0\n",
      "0.922938260478\n",
      "0.986121537993\n"
     ]
    }
   ],
   "source": [
    "metrics = MulticlassMetrics(sc.parallelize(predictionAndLabels))\n",
    "print metrics.confusionMatrix().toArray()\n",
    "print metrics.precision(1)\n",
    "print metrics.recall(1)\n",
    "print metrics.accuracy"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
