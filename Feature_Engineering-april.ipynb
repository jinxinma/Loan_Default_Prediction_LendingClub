{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature_Engineering\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import col, count, sum\n",
    "# Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.metrics import *\n",
    "import numpy as np\n",
    "from pyspark.ml.feature import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data and Convert to Spark Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'id,member_id,loan_amnt,funded_amnt,funded_amnt_inv,term,int_rate,installment,grade,sub_grade,emp_title,emp_length,home_ownership,annual_inc,verification_status,issue_d,loan_status,pymnt_plan,url,desc,purpose,title,zip_code,addr_state,dti,delinq_2yrs,earliest_cr_line,inq_last_6mths,mths_since_last_delinq,mths_since_last_record,open_acc,pub_rec,revol_bal,revol_util,total_acc,initial_list_status,out_prncp,out_prncp_inv,total_pymnt,total_pymnt_inv,total_rec_prncp,total_rec_int,total_rec_late_fee,recoveries,collection_recovery_fee,last_pymnt_d,last_pymnt_amnt,next_pymnt_d,last_credit_pull_d,collections_12_mths_ex_med,mths_since_last_major_derog,policy_code,application_type,annual_inc_joint,dti_joint,verification_status_joint,acc_now_delinq,tot_coll_amt,tot_cur_bal,open_acc_6m,open_il_6m,open_il_12m,open_il_24m,mths_since_rcnt_il,total_bal_il,il_util,open_rv_12m,open_rv_24m,max_bal_bc,all_util,total_rev_hi_lim,inq_fi,total_cu_tl,inq_last_12m']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read files\n",
    "sc.textFile(\"loan.csv\").take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data as dataframe\n",
    "loan_df=spark.read.csv(\"loan.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create response variable and features\n",
    "### 3.1 Remove some columns based on EDA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loan_df2=loan_df.select(\n",
    "    loan_df.loan_amnt.cast(\"float\"),\n",
    "    loan_df.funded_amnt.cast(\"float\"),\n",
    "    loan_df.funded_amnt_inv.cast(\"float\"),\n",
    "    loan_df.int_rate.cast(\"float\"),  #convert to float\n",
    "    loan_df.installment.cast(\"float\"), #convert to float\n",
    "    'grade',\n",
    "    'sub_grade',   # NEED TO BE DUMMIED\n",
    "    'emp_length',\n",
    "    'home_ownership', #group & make it dummy, done \n",
    "    loan_df.annual_inc.cast(\"float\"),\n",
    "    # 'issue_d',  #why comment out?\n",
    "    'loan_status', \n",
    "    # response variable (pending for change after group discussion)\n",
    "    'purpose',  #make it dummy\n",
    "#     'zip_code', #interesting, worth dummying, might run into problems tho\n",
    "#     'addr_state', #dummy\n",
    "    'verification_status',\n",
    "#     'initial_list_status',\n",
    "    loan_df.dti.cast(\"float\"),#float done\n",
    "    loan_df.delinq_2yrs.cast(\"integer\"),  \n",
    "    #take out NAs, 2? 1, 3, mostly 0\n",
    "    # 'earliest_cr_line',\n",
    "    loan_df.inq_last_6mths.cast(\"integer\"), #similar to delingq_2yr\n",
    "    loan_df.open_acc.cast(\"integer\"), \n",
    "    loan_df.pub_rec.cast(\"integer\"), #what is it? 0,1\n",
    "    loan_df.revol_bal.cast(\"float\"), #done\n",
    "    loan_df.revol_util.cast(\"float\"),#done\n",
    "    loan_df.total_acc.cast(\"integer\"),\n",
    "    #loan_df.last_credit_pull_d.cast(\"integer\"), #date\n",
    "    loan_df.acc_now_delinq.cast(\"integer\"),#ok\n",
    "    loan_df.tot_coll_amt.cast(\"float\"), #done\n",
    "    loan_df.tot_cur_bal.cast(\"float\"), #done\n",
    "    loan_df.total_rev_hi_lim.cast(\"integer\") #what is this\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create response variable and remove rows with no valid response variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# needs to fix that, encoding doesn't seem to be right\n",
    "\n",
    "def whetherpaid(x):\n",
    "    if x in ['Default', 'Charged Off', 'Does not meet the credit policy. Status:Charged Off']:\n",
    "        return 1\n",
    "    elif x in ['Does not meet the credit policy. Status:Fully Paid', 'Fully Paid']:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paidflag = udf(lambda x: whetherpaid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#subject to change\n",
    "loan_df3 = loan_df2.withColumn(\n",
    "    'paid_flag',\n",
    "    paidflag('loan_status').cast(\"integer\")\n",
    "        ).where(\"paid_flag != -1\").drop('loan_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loan_amnt: float (nullable = true)\n",
      " |-- funded_amnt: float (nullable = true)\n",
      " |-- funded_amnt_inv: float (nullable = true)\n",
      " |-- int_rate: float (nullable = true)\n",
      " |-- installment: float (nullable = true)\n",
      " |-- grade: string (nullable = true)\n",
      " |-- sub_grade: string (nullable = true)\n",
      " |-- emp_length: string (nullable = true)\n",
      " |-- home_ownership: string (nullable = true)\n",
      " |-- annual_inc: float (nullable = true)\n",
      " |-- purpose: string (nullable = true)\n",
      " |-- verification_status: string (nullable = true)\n",
      " |-- dti: float (nullable = true)\n",
      " |-- delinq_2yrs: integer (nullable = true)\n",
      " |-- inq_last_6mths: integer (nullable = true)\n",
      " |-- open_acc: integer (nullable = true)\n",
      " |-- pub_rec: integer (nullable = true)\n",
      " |-- revol_bal: float (nullable = true)\n",
      " |-- revol_util: float (nullable = true)\n",
      " |-- total_acc: integer (nullable = true)\n",
      " |-- acc_now_delinq: integer (nullable = true)\n",
      " |-- tot_coll_amt: float (nullable = true)\n",
      " |-- tot_cur_bal: float (nullable = true)\n",
      " |-- total_rev_hi_lim: integer (nullable = true)\n",
      " |-- paid_flag: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loan_df3.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Add more features\n",
    "#### 3.3.1 Create a numeric feature for \"emp_length\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def convert_to_int(s):\n",
    "    s = re.sub('\\\\D', '', s)  #remove any non-digital character\n",
    "    #\\d matches any digital, #\\D matches any non-digital\n",
    "    try:\n",
    "        return s\n",
    "    except ValueError:\n",
    "        return 'NaN'\n",
    "\n",
    "emp_to_num = udf(convert_to_int)\n",
    "loan_df4 = loan_df3.withColumn('emp_len',emp_to_num('emp_length').cast('integer')).drop('emp_length')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Create numeric variable for grade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+---------------+--------+-----------+-----+---------+--------------+----------+\n",
      "|loan_amnt|funded_amnt|funded_amnt_inv|int_rate|installment|grade|sub_grade|home_ownership|annual_inc|\n",
      "+---------+-----------+---------------+--------+-----------+-----+---------+--------------+----------+\n",
      "|        0|          0|              0|       0|          0|    0|        0|             0|         4|\n",
      "+---------+-----------+---------------+--------+-----------+-----+---------+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# count how many nulls in each column\n",
    "def count_null(c):\n",
    "    return sum(col(c).isNull().cast(\"integer\")).alias(c)\n",
    "\n",
    "exprs = [count_null(c) for c in loan_df4.columns[0:9]]\n",
    "loan_df4.agg(*exprs).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3 Create numeric variable for grade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def home_ownership_func(x):\n",
    "    if x in ['ANY','OTHER','NONE']:\n",
    "        return 'Other'\n",
    "    else: \n",
    "        return x\n",
    "\n",
    "home_ownership = udf(home_ownership_func)  #fixed a function\n",
    "loan_df5 = loan_df4.withColumn('home_ownership',home_ownership('home_ownership'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+\n",
      "|home_ownership| count|\n",
      "+--------------+------+\n",
      "|           OWN| 22282|\n",
      "|         Other|   228|\n",
      "|          RENT|107831|\n",
      "|      MORTGAGE|126598|\n",
      "+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loan_df5.select('home_ownership').groupBy('home_ownership').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.4 Add loan_inc_ratio feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_ratio(a, b):\n",
    "    try:\n",
    "        return a/float(b)\n",
    "    except TypeError:\n",
    "        return None\n",
    "    except ZeroDivisionError:\n",
    "        return None\n",
    "\n",
    "ratio = udf(calculate_ratio) #define a udf_function ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loan_df6 = loan_df5.withColumn(\n",
    "    'loan_inc_ratio',ratio('loan_amnt','annual_inc'\n",
    "                          ).cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loan_df7 = loan_df6.withColumn(\n",
    "    'instal_inc_ratio',\n",
    "    ratio('installment','annual_inc').cast('float'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.5 Add feature instal_inc_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_monthly_ratio(a, b):\n",
    "    try:\n",
    "        return a/(float(b)/12)\n",
    "    except TypeError:\n",
    "        return None\n",
    "    except ZeroDivisionError:\n",
    "        return None\n",
    "    \n",
    "monthly_ratio = udf(calculate_monthly_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loan_df8 = loan_df7.withColumn(\n",
    "    'instal_inc_ratio',\n",
    "    ratio('installment','annual_inc').cast('float'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.6 Create dummy variables\n",
    "* Use StringIndexer to encode a string column of labels to a column of label indices, and most frequent label gets index 0.\n",
    "\n",
    "* Use OneHotEncoder to convert indices into dummy vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purpose\n",
      "purpose\n",
      "grade\n",
      "grade\n",
      "sub_grade\n",
      "sub_grade\n",
      "verification_status\n",
      "verification_status\n",
      "home_ownership\n",
      "home_ownership\n"
     ]
    }
   ],
   "source": [
    "convert_list = [      \n",
    "               'purpose',\n",
    "               'grade',\n",
    "               'sub_grade',\n",
    "               'verification_status',\n",
    "               'home_ownership',\n",
    "                ]\n",
    "\n",
    "for item in convert_list:\n",
    "    print item\n",
    "    indexer = StringIndexer(inputCol=item, outputCol=item + 'Index')    \n",
    "    loan_df8 = indexer.fit(loan_df8).transform(loan_df8).drop(item)\n",
    "    onehotenc = OneHotEncoder(inputCol=item + 'Index', outputCol=item+\"-onehot\", dropLast=False)\n",
    "    # we can experiment with True\n",
    "    loan_df8 = onehotenc.transform(loan_df8).drop(item+'Index')\n",
    "    print item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loan_df8 = loan_df8.fillna(0.0, ['tot_coll_amt','tot_cur_bal', 'total_rev_hi_lim'])\n",
    "loan_df9 = loan_df8.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loan_amnt',\n",
       " 'funded_amnt',\n",
       " 'funded_amnt_inv',\n",
       " 'int_rate',\n",
       " 'installment',\n",
       " 'annual_inc',\n",
       " 'dti',\n",
       " 'delinq_2yrs',\n",
       " 'inq_last_6mths',\n",
       " 'open_acc',\n",
       " 'pub_rec',\n",
       " 'revol_bal',\n",
       " 'revol_util',\n",
       " 'total_acc',\n",
       " 'acc_now_delinq',\n",
       " 'tot_coll_amt',\n",
       " 'tot_cur_bal',\n",
       " 'total_rev_hi_lim',\n",
       " 'paid_flag',\n",
       " 'emp_len',\n",
       " 'loan_inc_ratio',\n",
       " 'instal_inc_ratio',\n",
       " 'purpose-onehot',\n",
       " 'grade-onehot',\n",
       " 'sub_grade-onehot',\n",
       " 'verification_status-onehot',\n",
       " 'home_ownership-onehot']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_df9.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loan_df_final = loan_df9.select(\n",
    "    'paid_flag',\n",
    "    'loan_amnt',\n",
    "    'funded_amnt',\n",
    "    'funded_amnt_inv',\n",
    "    'int_rate',\n",
    "    'installment',\n",
    "    'annual_inc',\n",
    "    'dti',\n",
    "    'delinq_2yrs',\n",
    "    'inq_last_6mths',\n",
    "    'open_acc',\n",
    "    'pub_rec',\n",
    "    'revol_bal',\n",
    "    'revol_util',\n",
    "    'total_acc',\n",
    "    'acc_now_delinq',\n",
    "    'tot_coll_amt',\n",
    "    'tot_cur_bal',\n",
    "    'total_rev_hi_lim',\n",
    "    'emp_len',\n",
    "    'loan_inc_ratio',\n",
    "    'instal_inc_ratio',\n",
    "    'purpose-onehot',\n",
    "    'grade-onehot',\n",
    "    'sub_grade-onehot',\n",
    "    'verification_status-onehot',\n",
    "    'home_ownership-onehot'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- paid_flag: integer (nullable = true)\n",
      " |-- loan_amnt: float (nullable = true)\n",
      " |-- funded_amnt: float (nullable = true)\n",
      " |-- funded_amnt_inv: float (nullable = true)\n",
      " |-- int_rate: float (nullable = true)\n",
      " |-- installment: float (nullable = true)\n",
      " |-- annual_inc: float (nullable = true)\n",
      " |-- dti: float (nullable = true)\n",
      " |-- delinq_2yrs: integer (nullable = true)\n",
      " |-- inq_last_6mths: integer (nullable = true)\n",
      " |-- open_acc: integer (nullable = true)\n",
      " |-- pub_rec: integer (nullable = true)\n",
      " |-- revol_bal: float (nullable = true)\n",
      " |-- revol_util: float (nullable = true)\n",
      " |-- total_acc: integer (nullable = true)\n",
      " |-- acc_now_delinq: integer (nullable = true)\n",
      " |-- tot_coll_amt: float (nullable = false)\n",
      " |-- tot_cur_bal: float (nullable = false)\n",
      " |-- total_rev_hi_lim: integer (nullable = true)\n",
      " |-- emp_len: integer (nullable = true)\n",
      " |-- loan_inc_ratio: float (nullable = true)\n",
      " |-- instal_inc_ratio: float (nullable = true)\n",
      " |-- purpose-onehot: vector (nullable = true)\n",
      " |-- grade-onehot: vector (nullable = true)\n",
      " |-- sub_grade-onehot: vector (nullable = true)\n",
      " |-- verification_status-onehot: vector (nullable = true)\n",
      " |-- home_ownership-onehot: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loan_df_final.take(1)\n",
    "loan_df_final.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Splitting and Formatting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=0, loan_amnt=5000.0, funded_amnt=5000.0, funded_amnt_inv=4975.0, int_rate=10.649999618530273, installment=162.8699951171875, annual_inc=24000.0, dti=27.649999618530273, delinq_2yrs=0, inq_last_6mths=1, open_acc=3, pub_rec=0, revol_bal=13648.0, revol_util=83.69999694824219, total_acc=9, acc_now_delinq=0, tot_coll_amt=0.0, tot_cur_bal=0.0, total_rev_hi_lim=0, emp_len=10, loan_inc_ratio=0.2083333283662796, instal_inc_ratio=0.006786249577999115, purpose-onehot=SparseVector(265, {1: 1.0}), grade-onehot=SparseVector(7, {0: 1.0}), sub_grade-onehot=SparseVector(35, {3: 1.0}), verification_status-onehot=SparseVector(3, {0: 1.0}), home_ownership-onehot=SparseVector(4, {1: 1.0})),\n",
       " Row(label=1, loan_amnt=2500.0, funded_amnt=2500.0, funded_amnt_inv=2500.0, int_rate=15.270000457763672, installment=59.83000183105469, annual_inc=30000.0, dti=1.0, delinq_2yrs=0, inq_last_6mths=5, open_acc=3, pub_rec=0, revol_bal=1687.0, revol_util=9.399999618530273, total_acc=4, acc_now_delinq=0, tot_coll_amt=0.0, tot_cur_bal=0.0, total_rev_hi_lim=0, emp_len=1, loan_inc_ratio=0.0833333358168602, instal_inc_ratio=0.0019943334627896547, purpose-onehot=SparseVector(265, {6: 1.0}), grade-onehot=SparseVector(7, {1: 1.0}), sub_grade-onehot=SparseVector(35, {7: 1.0}), verification_status-onehot=SparseVector(3, {2: 1.0}), home_ownership-onehot=SparseVector(4, {1: 1.0}))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Split the data into training and test sets (30% held out for testing)\n",
    "loan_df=loan_df_final.withColumnRenamed('paid_flag','label')\n",
    "loan_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# va=VectorAssembler(outputCol='features',inputCols=loan_df.columns[:])\n",
    "va=VectorAssembler(outputCol='features',inputCols=loan_df.columns[1:])\n",
    "data=va.transform(loan_df).select('features','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=SparseVector(335, {0: 5000.0, 1: 5000.0, 2: 4975.0, 3: 10.65, 4: 162.87, 5: 24000.0, 6: 27.65, 8: 1.0, 9: 3.0, 11: 13648.0, 12: 83.7, 13: 9.0, 18: 10.0, 19: 0.2083, 20: 0.0068, 22: 1.0, 286: 1.0, 296: 1.0, 328: 1.0, 332: 1.0}), label=0),\n",
       " Row(features=SparseVector(335, {0: 2500.0, 1: 2500.0, 2: 2500.0, 3: 15.27, 4: 59.83, 5: 30000.0, 6: 1.0, 8: 5.0, 9: 3.0, 11: 1687.0, 12: 9.4, 13: 4.0, 18: 1.0, 19: 0.0833, 20: 0.002, 27: 1.0, 287: 1.0, 300: 1.0, 330: 1.0, 332: 1.0}), label=1),\n",
       " Row(features=SparseVector(335, {0: 2400.0, 1: 2400.0, 2: 2400.0, 3: 15.96, 4: 84.33, 5: 12252.0, 6: 8.72, 8: 2.0, 9: 2.0, 11: 2956.0, 12: 98.5, 13: 10.0, 18: 10.0, 19: 0.1959, 20: 0.0069, 26: 1.0, 287: 1.0, 303: 1.0, 329: 1.0, 332: 1.0}), label=0)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(335,[0,1,2,3,4,5...|    0|\n",
      "|(335,[0,1,2,3,4,5...|    1|\n",
      "|(335,[0,1,2,3,4,5...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating Training and Test Data by random split 0.8,0.2\n",
    "data_sets=data.randomSplit([0.8,0.2])\n",
    "data_test=data_sets[1].cache()\n",
    "data_train=data_sets[0].cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40467"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.filter('label=0').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8849"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.filter('label=1').count()  #fraud rate is 22% for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161464"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.filter('label=0').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35677"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.filter('label=1').count() #fraud rate is 16% for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bootstrap oversample to balance training data\n",
    "\n",
    "data_train_paid = data_train.filter(data_train.label == 0)\n",
    "data_train_not_paid = data_train.filter(data_train.label == 1)\n",
    "\n",
    "num_samples_train = data_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197141\n",
      "161464\n",
      "35677\n"
     ]
    }
   ],
   "source": [
    "print num_samples_train   #total 197,414 number of observations\n",
    "half_num_samples_train = num_samples_train / 2  #98,707\n",
    "\n",
    "print data_train_paid.count() #paid  161,634\n",
    "print data_train_not_paid.count() #non-paid 35780\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train_paid = data_train_paid.sample(True, float(half_num_samples_train) / data_train_paid.count()) \n",
    "#0.6, among paid samples, we sample 0.6 of it\n",
    "data_train_not_paid = data_train_not_paid.sample(True, float(half_num_samples_train) / data_train_not_paid.count())\n",
    "#0.2, among unpaid samples, we sample 0.2 of it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161464\n",
      "35677\n"
     ]
    }
   ],
   "source": [
    "print data_train.where(data_train.label == 0).count()\n",
    "print data_train.where(data_train.label == 1).count()\n",
    "# now data_train should have balanced 'paid' and 'unpaid' class, as we use 0.5,0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197211"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = data_train_paid.union(data_train_not_paid)  \n",
    "#union two random sample sets together, paid & unpaid\n",
    "data_train.count() #total observations remain close enough to the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cross Valiation\n",
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "from pyspark.ml.tuning import TrainValidationSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit random forest\n",
    "rf=RandomForestClassifier()\n",
    "evaluator_rf=BinaryClassificationEvaluator()\n",
    "cv=CrossValidator().setEstimator(rf).setEvaluator(evaluator_rf).setNumFolds(5)\n",
    "paramGrid=ParamGridBuilder().addGrid(rf.numTrees,[21,31]).addGrid(rf.maxDepth,[2,15,20]).build()\n",
    "\n",
    "cv.setEstimatorParamMaps(paramGrid)\n",
    "cvmodel_rf=cv.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_rf=cvmodel_rf.bestModel.transform(data_test)\n",
    "prediction_list_rf = predictions_rf.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictionAndLabels_rf = []\n",
    "for item in prediction_list_rf:\n",
    "    predictionAndLabels_rf.append((float(item[4]), float(item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC:0.698015961983\n"
     ]
    }
   ],
   "source": [
    "score=evaluator_rf.evaluate(predictions_rf)\n",
    "print evaluator_rf.getMetricName()+\":\"+str(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 25858.  14609.]\n",
      " [  3162.   5687.]]\n",
      "0.280202995664\n",
      "0.642671488304\n",
      "0.639650417714\n"
     ]
    }
   ],
   "source": [
    "metrics_rf = MulticlassMetrics(sc.parallelize(predictionAndLabels_rf))\n",
    "print metrics_rf.confusionMatrix().toArray()\n",
    "print metrics_rf.precision(1)\n",
    "print metrics_rf.recall(1)\n",
    "print metrics_rf.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfmodel=cvmodel_rf.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 0.1635414979369767),\n",
       " (288, 0.09794306268220121),\n",
       " (20, 0.063330108507469271),\n",
       " (19, 0.047106025738293922),\n",
       " (6, 0.041730836865062966),\n",
       " (5, 0.038222267221845872),\n",
       " (12, 0.037286111683942656),\n",
       " (290, 0.030406604854939401),\n",
       " (286, 0.02752545919465035),\n",
       " (289, 0.025652809866268424),\n",
       " (16, 0.023347728552965775),\n",
       " (291, 0.022225202899798735),\n",
       " (13, 0.022149339398023913),\n",
       " (1, 0.021683998520729147),\n",
       " (11, 0.021491230625873214)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_list = list(enumerate(rfmodel.featureImportances))\n",
    "importance_list.sort(key=lambda tup: -tup[1])\n",
    "top_importances = importance_list[:15]\n",
    "top_importances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "lr=LogisticRegression()\n",
    "evaluator=BinaryClassificationEvaluator()\n",
    "\n",
    "cv=CrossValidator().setEstimator(lr).setEvaluator(evaluator).setNumFolds(5)\n",
    "paramGrid=ParamGridBuilder().addGrid(lr.maxIter,[100]).addGrid(lr.regParam,[0.1,0.01,0.001,1]).build()\n",
    "\n",
    "cv.setEstimatorParamMaps(paramGrid)\n",
    "cvmodel=cv.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cvmodel.bestModel.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions=cvmodel.bestModel.transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|(335,[0,1,2,3,4,5...|    0|[-0.8693901683396...|[0.29538121112739...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 1 row\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print predictions.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC:0.708674186272\n"
     ]
    }
   ],
   "source": [
    "score=evaluator.evaluate(cvmodel.bestModel.transform(data_test))\n",
    "print evaluator.getMetricName()+\":\"+str(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_list = predictions.collect()\n",
    "predictionAndLabels = []\n",
    "for item in prediction_list:\n",
    "    predictionAndLabels.append((float(item[4]), float(item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 25809.  14658.]\n",
      " [  3000.   5849.]]\n",
      "0.285219681085\n",
      "0.660978641654\n",
      "0.641941763322\n"
     ]
    }
   ],
   "source": [
    "metrics = MulticlassMetrics(sc.parallelize(predictionAndLabels))\n",
    "print metrics.confusionMatrix().toArray()\n",
    "print metrics.precision(1)\n",
    "print metrics.recall(1)\n",
    "print metrics.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
